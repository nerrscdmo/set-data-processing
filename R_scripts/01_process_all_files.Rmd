---
title: "National SET Data Processing"
author: "Kim Cressman"
date: "`r Sys.Date()`"
output: 
        html_document:
                toc: yes
---

6/9/2025 - updating all code to process SETr data for a dashboard. Will incorporate flexibility so hopefully this can be used on updated files in the future. For the moment, these are all files from SETr; many of which end in 2016 or 2017.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = FALSE, warning = FALSE}

library(dplyr)
library(tidyr)
library(purrr)
library(readxl)
library(stringr)
library(lubridate)
library(here)
library(nlme)
library(janitor)
```


# Tidy the individual raw data files  

Find and list the raw files.  

```{r}
raw_path <- here::here("data", "01_reserve_raw")
raw_files <- dir(raw_path, pattern = "set.xls")
```


Process them and output them to the `processed_reserve_level` directory.  

```{r}
processed_path <- here::here("data", "02_reserve_processed")
sourced_path <- here::here("R_scripts", "sourced")
processing_script <- here::here(sourced_path, "01_natl_process_raw_data.R")

# for each raw file, source the processing script
for(i in seq_along(raw_files)){
        file_path <- here::here(raw_path, raw_files[i])
        source(processing_script)
        message(paste("\n", file_out, "\nhas been produced \n"))
}

message("\n \nFinished with file processing \n")
```


# Combine the individual tidy files into one  


Now read them all in and combine them into one big file.  

```{r}
processed_files <- dir(processed_path, pattern = "processed.csv")

processed_list <- list()

for(i in seq_along(processed_files)){
        # read in file
        file_path <- here::here(processed_path, processed_files[i])
        dat <- read.csv(file_path, stringsAsFactors = FALSE)
        
        # if there isn't a column for reserve, pull it from the file name
        if(!exists("reserve", dat)){
                reserve <- substr(processed_files[i], 1, 3)
                dat$reserve <- toupper(reserve)
        }
        
        # select only the common columns for this project
        dat <- dat %>% 
                mutate_at(c("reserve", "set_id", "arm_position"), as.character) %>% 
                select(reserve,
                       set_id, 
                       year, month, day, 
                       arm_position, 
                       arm_qaqc_code, 
                       pin_number, 
                       starts_with("height"),    # get either mm or cm
                       qaqc_code)
        processed_list[[i]] <- dat
}
```


See the names in all the files.  

```{r}
purrr::map(processed_list, ~names(.x))
```

Bind them into one data frame.  

```{r}
dat_all <- bind_rows(processed_list)

glimpse(dat_all)

unique(dat_all$set_id)
```


Get all of the pin heights into mm and get rid of anything where date doesn't exist.

```{r}
# this only works because we have some of each
# it threw an error when I was testing with only files that have height_mm
dat_all2 <- dat_all %>% 
        mutate(pin_height = case_when(!is.na(height_mm) ~ height_mm,
                                      !is.na(height_cm) ~ 10 * height_cm),
               date = ymd(paste(year, month, day, sep = "\\/")),
               date2 = decimal_date(date),
               arm_pin = paste0(arm_position, "-", pin_number)) %>% 
        select(-starts_with("height")) %>% 
        filter(!is.na(date))

# some of these failed to parse; check out what's going on
failed_parsing <- anti_join(dat_all, dat_all2)
glimpse(failed_parsing)

# looks like a bunch of missing measurements - because there are no dates
# make sure
sum(is.na(dat_all$year))
sum(is.na(dat_all$year)) == nrow(failed_parsing)
# okay
```

Write out to a csv for later use.  

```{r}
out_path <- here::here("data", "03_combined_processed", "all_sites.csv")
write.csv(dat_all2, out_path, row.names = FALSE)
```


# Read in and combine metadata files  

Find and list the raw files.  

```{r}
raw_path <- here::here("data", "01b_reserve_metadata")
raw_files <- dir(raw_path, pattern = "set_metadata.xls")
```

Read them in and combine them.  

```{r}
combined_list <- list()

for(i in seq_along(raw_files)){
        in_path <- here::here(raw_path, raw_files[i])
        dat <- read_excel(in_path) %>% 
                clean_names() %>% 
                select(reserve,
                       set_id = unique_set_id,
                       user_friendly_set_name,
                       numerical_order,
                       set_type,
                       lat = latitude_dec_deg,
                       long = longitude_dec_deg,
                       navd88_ground = surface_elevation_ground_navd88,
                       navd88_receiver = surface_elevation_receiver_navd88,
                       starts_with("co_dominant_species"),
                       general_salinity) %>% 
                mutate_at(c("reserve", "set_id", "user_friendly_set_name", "general_salinity", "navd88_ground", "navd88_receiver"), as.character) 
        combined_list[[i]] <- dat
}

metadat_all <- bind_rows(combined_list)
```

Write that out.  

```{r}
out_path <- here::here("data", "03_combined_processed", "all_sites_metadata.csv")
write.csv(metadat_all, out_path, row.names = FALSE)
```

